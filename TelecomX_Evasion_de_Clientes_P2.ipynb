{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DXBPIKIN1WrU",
        "oJuxvchfMi_m",
        "TfQ9NkfGfkP9",
        "aQYsoKI7Xpqo",
        "2JSzaC_VXLoB",
        "rgwXxN1lzbKa",
        "xTAbGXTyTGai",
        "L_JY_JFQx4qu",
        "yPDzJHoQPmkP",
        "99uKUJNo6WSR",
        "2g1eCBiv62ME",
        "912o1Jl5DvNv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AVIDALESB/TelecomX-Evasion-de-Clientes-P2/blob/main/TelecomX_Evasion_de_Clientes_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Extracci칩n del Archivo Tratado***\n",
        "\n",
        "> Agregar bloque entrecomillado\n",
        "\n"
      ],
      "metadata": {
        "id": "DXBPIKIN1WrU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_-cUTTaxLPe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos = pd.read_csv('/content/df.csv')"
      ],
      "metadata": {
        "id": "jdvwE3MY1s1E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "259c6704-f00f-4710-8abf-d6f037eb00e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/df.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3858360656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/df.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos['g칠nero'] = datos['g칠nero'].map({'Masculino': 0, 'Femenino': 1})"
      ],
      "metadata": {
        "id": "a1hTFZGa81xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.rename(columns={'cuidadano_mayor': 'ciudadano_mayor'})"
      ],
      "metadata": {
        "id": "xSQMaDULLMdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "id": "tcDU2nwc10jb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "bgWdUOjK19bd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.isnull().sum()"
      ],
      "metadata": {
        "id": "bMcVQq2h7hu0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Eliminaci칩n de las Columnas Irrelevantes***"
      ],
      "metadata": {
        "id": "oJuxvchfMi_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(datos.nunique().sort_values())"
      ],
      "metadata": {
        "id": "uMJ_prdmMjtm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_unicas = [col for col in datos.columns if datos[col].nunique() == 1]\n",
        "print(f'Las columnas con valores 칰nicos son: {columnas_unicas}')"
      ],
      "metadata": {
        "id": "6oHQV6IdMnHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacion = datos.select_dtypes(include=['float64', 'int64']).corr().abs()\n",
        "correlacion"
      ],
      "metadata": {
        "id": "AeG1XpBlMnn1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado que cuentas_diarias y cargos_mensuales tienen la misma correlatividad, conviene eliminar cuentas_diarias.\n",
        "# Otras columnas que se eliminar치n ser치n id_cliente porque tiene identificadores 칰nicos y cantidad_servicios por su alta correlaci칩n en columnas irrelevantes para relacionarlas con churn.\n",
        "# Tambi칠n, otras columnas que se eliminar치 por su baja correlacion con churn y el resto de columnas ser치n servicio_telefonico y g칠nero.\n",
        "# Si bien cargos_totales puede ser 칰til con churn, su multicolinealidad del 0.82 con meses_de_contrato la hace una columna inviable para el modelo."
      ],
      "metadata": {
        "id": "cHZJwW1sMnlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reducido = datos.drop(columns = ['id_cliente', 'cuentas_diarias', 'cantidad_servicios', 'servicio_telefonico', 'cargos_totales', 'g칠nero'])\n",
        "df_reducido.info()"
      ],
      "metadata": {
        "id": "halwRKDdMnix",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Verificaci칩n de la Proporci칩n de Cancelaci칩n (Churn)***"
      ],
      "metadata": {
        "id": "TfQ9NkfGfkP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "valores = df_reducido['churn'].value_counts()\n",
        "porcentajes = df_reducido['churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "df_aux = df_reducido['churn'].map({0: 'Permanece', 1: 'Abandon칩'}).to_frame(name='Estado')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(7, 7))\n",
        "colores = ['#0083d5', '#d56e00']\n",
        "\n",
        "ax = sns.countplot(x='Estado', data=df_aux, color=None)\n",
        "for patch, color in zip(ax.patches, colores):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "plt.title('PROPORCI칍N DE CANCELACI칍N (CHURN)', fontsize=14, fontweight='bold', loc='center')\n",
        "plt.xlabel('ESTADO DEL CLIENTE', fontsize=10, fontweight='bold')\n",
        "plt.ylabel('N칔MERO DE CLIENTES', fontsize=10, fontweight='bold')\n",
        "\n",
        "for p in ax.patches:\n",
        "    cantidad = int(p.get_height())\n",
        "    porcentaje = cantidad / len(df_reducido['churn']) * 100\n",
        "    ax.annotate(f'{cantidad} / {porcentaje:.1f}%',\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='bottom', fontsize=10, color='black',\n",
        "                xytext=(0, 1), textcoords='offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zMyhWpPJmWQ0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***An치lisis de Correlaci칩n***"
      ],
      "metadata": {
        "id": "aQYsoKI7Xpqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df_reducido.select_dtypes(include=['float64', 'int64']).corr().abs()"
      ],
      "metadata": {
        "id": "85YiJyKsYQaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.imshow(\n",
        "    df_corr,\n",
        "    text_auto=\".2f\",\n",
        "    color_continuous_scale=\"viridis\",\n",
        "    aspect=\"auto\",\n",
        "    title=\"MATRIZ DE CORRELACI칍N\"\n",
        ")\n",
        "fig.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RaWUH2ryZq6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Al analizar la primera columna de la matriz, se puede identificar claramente los factores m치s influyentes.\n",
        "# El predictor principal es meses_de_contrato con una correlaci칩n del 0.34. La interpretaci칩n es que a mayor antig칲edad, menor es la probabilidad de cancelar.\n",
        "# Despu칠s hay predictores secundarios cuyo impacto es moderado. Por ejemplo: cargos_mensuales y factura_en_linea (ambas con 0.18) mantienen un peso considerable.\n",
        "# Ambos intuyen que los clientes con cargos m치s altos o con factura online tienen una leve tendencia mayor a cancelar.\n",
        "# El grupo de variables demogr치ficas ahora tiene m치s protagonismo (dependientes con 0.15, pareja con 0.14 y ciudadano_mayor con 0.14), aunque su impacto individual es d칠bil.\n",
        "# En conjunto le dan al modelo un perfil claro del cliente. Por ejemplo: Ser un ciudadano mayor, tener pareja o dependientes tiene una influencia positiva muy leve en la probabilidad de abandono.\n",
        "\n",
        "# Otras conclusiones a sacar son que la correlaci칩n m치s fuerte en toda la matriz es entre pareja y dependientes con 0.45, por lo que quienen tengan pareja son m치s propensos a tener dependientes.\n",
        "# Otra correlaci칩n moderada es entre pareja y meses_de_contrato con 0.38, esto sugiere que los clientes con pareja tienden a tener contratos de mayor duraci칩n.\n",
        "# Y por 칰ltimo, la correlaci칩n entre factura_en_linea y cargos_mensuales es moderada con 0.35, eso indica que los clientes con cargos mensuales m치s altos son m치s propensos a usar la facturaci칩n en l칤nea."
      ],
      "metadata": {
        "id": "4D3t621fkIIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***An치lisis Dirigido***"
      ],
      "metadata": {
        "id": "2JSzaC_VXLoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import Line2D\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "ax = sns.boxplot(\n",
        "    data=df_reducido,\n",
        "    x='churn',\n",
        "    y='meses_de_contrato',\n",
        "    hue='churn',\n",
        "    palette={0: '#0083d5', 1: '#d56e00'},\n",
        "    legend=False,\n",
        "    medianprops={'linewidth': 2}\n",
        ")\n",
        "\n",
        "for i, (name, group) in enumerate(df_reducido.groupby('churn')):\n",
        "    ax.hlines(\n",
        "        y=group['meses_de_contrato'].mean(),\n",
        "        xmin=i - 0.4,\n",
        "        xmax=i + 0.4,\n",
        "        color='cyan',\n",
        "        linestyle='--',\n",
        "        linewidth = 2\n",
        "    )\n",
        "\n",
        "plt.title(\"DISTRIBUCI칍N DE LOS MESES DE CONTRATO SEG칔N LA CANCELACI칍N\", fontsize=14, fontweight='bold', loc = 'center')\n",
        "plt.xlabel(\"ESTADO DEL CLIENTE\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"MESES DE CONTRATO\", fontsize=12, fontweight='bold')\n",
        "\n",
        "legend_elements = [\n",
        "    Line2D([0], [0], color='cyan', linestyle='--', label='Media'),\n",
        "    Line2D([0], [0], color='black', label='Mediana')\n",
        "]\n",
        "\n",
        "ax.legend(handles=legend_elements, loc='upper center')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XAf5UESheP9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En el grupo 0 la mediana es ligeramente m치s alta que la media (aunque ambas tienen casi el mismo valor, aproximadamente 38 meses).\n",
        "# Hay una amplia dispersi칩n en el rango de los meses (De 1 a m치s de 70), lo que indica una clientela con permanencias muy diversas.\n",
        "# La mayor칤a de los clientes que no cancelaron han permanecido mucho m치s tiempo con la empresa.\n",
        "# Mientras tanto, en el grupo 1, la mediana est치 entre 10 y 12 meses y la media est치 entre 19 y 20 meses, por lo que es m치s alta que la mediana.\n",
        "# Los clientes que cancelan tienden a tener menos meses de contrato.\n",
        "\n",
        "# Esto esto indica una relaci칩n entre las variables: Cuanto m치s meses de contrato, menor es la probabilidad de cancelaci칩n, por lo que la retenci칩n de largo plazo disminuye la tasa de churn."
      ],
      "metadata": {
        "id": "OYGwt7zyjSds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import Line2D\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "ax = sns.boxplot(\n",
        "    data=df_reducido,\n",
        "    x='churn',\n",
        "    y='cargos_mensuales',\n",
        "    hue='churn',\n",
        "    palette={0: '#0083d5', 1: '#d56e00'},\n",
        "    legend=False,\n",
        "    medianprops={'linewidth': 2}\n",
        ")\n",
        "\n",
        "for i, (name, group) in enumerate(df_reducido.groupby('churn')):\n",
        "    ax.hlines(\n",
        "        y=group['cargos_mensuales'].mean(),\n",
        "        xmin=i - 0.4,\n",
        "        xmax=i + 0.4,\n",
        "        color='cyan',\n",
        "        linestyle='--',\n",
        "        linewidth = 2\n",
        "    )\n",
        "\n",
        "plt.title(\"DISTRIBUCI칍N DE LOS CARGOS MENSUALES SEG칔N LA CANCELACI칍N\", fontsize=14, fontweight='bold', loc = 'center')\n",
        "plt.xlabel(\"ESTADO DEL CLIENTE\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"CARGOS MENSUALES\", fontsize=12, fontweight='bold')\n",
        "\n",
        "legend_elements = [\n",
        "    Line2D([0], [0], color='cyan', linestyle='--', label='Media'),\n",
        "    Line2D([0], [0], color='black', label='Mediana')\n",
        "]\n",
        "\n",
        "ax.legend(handles=legend_elements, loc='upper center')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zaB6DyW5iNdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En este grupo 0 la mediana de cargos mensuales es cercana a 65 al igual que la media, solo que esta es m칤nimamente menor a la mediana (aproximadamente 62).\n",
        "# Existe una distribuci칩n amplia pero es relativamente m치s baja en valores.\n",
        "# En cambio, en el grupo 1 la mediana ronda casi los 80 (es mayor que el grupo que no cancel칩) y la media ronda si los 75, siendo m치s alto que el grupo 0.\n",
        "# Esto demuestra que muchos clientes que cancelan tienen cargos mensuales m치s altos.\n",
        "\n",
        "# En este boxplot existe una relaci칩n inversa entre las variables: Los clientes con cargos m치s altos tienden a cancelar m치s.\n",
        "# Esto podr칤a deberse a una percepci칩n de alto costo o baja percepci칩n de valor por el precio pagado."
      ],
      "metadata": {
        "id": "U8S8oTDsrdn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Separaci칩n de los Datos***"
      ],
      "metadata": {
        "id": "rgwXxN1lzbKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reducido.columns"
      ],
      "metadata": {
        "id": "Er_DacP0hy_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reducido"
      ],
      "metadata": {
        "id": "XVl5p1i-hy7_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_reducido.drop('churn', axis = 1)\n",
        "y = df_reducido['churn']"
      ],
      "metadata": {
        "id": "vLHkJzMghy5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N7q3axlUhyuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tdBEUmeZh2je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify = y, random_state=42)"
      ],
      "metadata": {
        "id": "iIF7dY_Zzem4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_categoricas = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "columnas_numericas = ['meses_de_contrato', 'cargos_mensuales']"
      ],
      "metadata": {
        "id": "Y2MsPPT1lNtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Encoding***"
      ],
      "metadata": {
        "id": "xTAbGXTyTGai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "i500IcOcTUD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = make_column_transformer((OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas), (StandardScaler(), columnas_numericas), remainder='passthrough', sparse_threshold=0)"
      ],
      "metadata": {
        "id": "xNNqeQ75Tdfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded = one_hot.fit_transform(X_train)\n",
        "X_test_encoded = one_hot.transform(X_test)"
      ],
      "metadata": {
        "id": "9NEgdZ0eTdcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot.get_feature_names_out()"
      ],
      "metadata": {
        "id": "RMtdaN0LTdaG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df = pd.DataFrame(X_train_encoded, columns = one_hot.get_feature_names_out())\n",
        "X_train_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7gtrHKsSTdXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df.info()"
      ],
      "metadata": {
        "id": "12sWeu2gTdVL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_df = pd.DataFrame(X_test_encoded, columns=one_hot.get_feature_names_out())\n",
        "X_test_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Rpxqf-R7iTOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_df.info()"
      ],
      "metadata": {
        "id": "t2-qd_9-ie2O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_corr = X_train_df.copy()\n",
        "X_train_corr['churn'] = y_train.reset_index(drop=True)\n",
        "\n",
        "correlaciones = X_train_corr.corr()['churn'].sort_values(ascending=False)\n",
        "print(correlaciones)"
      ],
      "metadata": {
        "id": "bN2be346G7n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "modelo_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
        "selector = RFECV(estimator=modelo_l1, step=1, cv=5, scoring='accuracy')\n",
        "selector.fit(X_train_df, y_train)\n",
        "\n",
        "selected_features = X_train_df.columns[selector.support_]\n",
        "print(\"N칰mero 칩ptimo de variables:\", selector.n_features_)"
      ],
      "metadata": {
        "id": "FS880Y5rPixe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "modelo_base = LogisticRegression(penalty='l1', solver='liblinear', C = 10, random_state=42)\n",
        "selector = RFE(estimator=modelo_base, n_features_to_select=29)\n",
        "\n",
        "selector.fit(X_train_df, y_train)\n",
        "selected_features_mask = selector.support_\n",
        "selected_features = X_train_df.columns[selected_features_mask]\n",
        "\n",
        "X_train_selected = X_train_df[selected_features]\n",
        "X_test_selected = X_test_df[selected_features]\n",
        "\n",
        "print(\"Las variables seleccionadas son:\")\n",
        "print(selected_features)"
      ],
      "metadata": {
        "id": "5tOZhrqgNjEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Balanceo de las Clases***"
      ],
      "metadata": {
        "id": "L_JY_JFQx4qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_bal, y_train_bal = ros.fit_resample(X_train_selected, y_train)\n",
        "\n",
        "print(\"Distribuci칩n original:\", Counter(y))\n",
        "print(\"Distribuci칩n del entrenamiento antes del balanceo:\", Counter(y_train))\n",
        "print(\"Distribuci칩n del entrenamiento balanceado:\", Counter(y_train_bal))\n",
        "\n",
        "counter = Counter(y_train_bal)\n",
        "if len(set(counter.values())) == 1:\n",
        "    print(\"Las clases est치n perfectamente balanceadas.\")\n",
        "else:\n",
        "    print(\"Las clases NO est치n balanceadas perfectamente.\")"
      ],
      "metadata": {
        "id": "ZXH0AwCpyCJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Normalizaci칩n o Estandarizaci칩n***"
      ],
      "metadata": {
        "id": "yPDzJHoQPmkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En esta etapa, no hace falta normalizar o estandarizar los datos antes del entrenamiento de modelos ya que si bien hay algunos que lo necesitan.\n",
        "# La realidad es que ya se aplic칩 la estandarizaci칩n autom치ticamente a las variables num칠ricas mediante StandardScaler dentro del make_column_transformer.\n",
        "# Eso si, las variables binarias ('ciudadano_mayor', 'pareja', 'dependientes' y 'factura_en_linea') no se estandarizaron debido a que su escala no afecta a los algoritmos"
      ],
      "metadata": {
        "id": "9zyhRWqHm6ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Creaci칩n y Evaluaci칩n de los Modelos***"
      ],
      "metadata": {
        "id": "99uKUJNo6WSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluar_modelo(y_test, y_pred):\n",
        "  print(\"Resultados para el modelo:\")\n",
        "  print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "  print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
        "  print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
        "  print(f\"F1: {f1_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "-uYGCxMnXYPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "modelo = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=10,\n",
        "    class_weight= 'balanced',\n",
        "    solver='liblinear',\n",
        "    max_iter=5000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo.fit(X_train_bal, y_train_bal)\n",
        "y_modelo_lr = modelo.predict(X_test_selected)\n",
        "evaluar_modelo(y_test, y_modelo_lr)"
      ],
      "metadata": {
        "id": "07S6bih8pAQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "modelo2 = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=100,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=10,\n",
        "    max_features='log2',\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo2.fit(X_train_bal, y_train_bal)\n",
        "y_modelo_rf = modelo2.predict(X_test_selected)\n",
        "evaluar_modelo(y_test, y_modelo_rf)"
      ],
      "metadata": {
        "id": "rAbNNXmllBU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "modelo3 = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo3.fit(X_train_bal, y_train_bal)\n",
        "y_modelo_gb = modelo3.predict(X_test_selected)\n",
        "evaluar_modelo(y_test, y_modelo_gb)"
      ],
      "metadata": {
        "id": "Q04L3BVwnRL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import numpy as np\n",
        "\n",
        "modelo_rf = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=100,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=10,\n",
        "    max_features='log2',\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo_voto = VotingClassifier(estimators=[('rf', modelo_rf), ('gb', modelo_gb)],voting='soft')\n",
        "modelo_voto.fit(X_train_bal, y_train_bal)\n",
        "y_proba = modelo_voto.predict_proba(X_test_selected)[:, 1]\n",
        "umbral = 0.45\n",
        "y_pred = (y_proba >= umbral).astype(int)\n",
        "evaluar_modelo(y_test, y_pred)"
      ],
      "metadata": {
        "id": "OZESRJb52UEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred, name = 'Modelo H칤brido');"
      ],
      "metadata": {
        "id": "iPoVGTE8bTsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
        "visualizacion_matriz = ConfusionMatrixDisplay(confusion_matrix = matriz_confusion, display_labels = ['Se qued칩', 'Abandon칩'])\n",
        "visualizacion_matriz.plot();"
      ],
      "metadata": {
        "id": "xUbWIii9eAaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***An치lisis de la Importancia de las Variables seg칰n los Modelos***"
      ],
      "metadata": {
        "id": "2g1eCBiv62ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_importance = modelo2.feature_importances_\n",
        "gb_importance = modelo3.feature_importances_\n",
        "\n",
        "feature_names = X_train_selected.columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'Variable': feature_names,\n",
        "    'RandomForest': rf_importance,\n",
        "    'GBM': gb_importance\n",
        "})\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "rf_plot_data = importance_df.sort_values('RandomForest', ascending=False).head(15)\n",
        "sns.barplot(x='RandomForest', y='Variable', data=rf_plot_data, ax=axes[0], palette='viridis', hue='Variable', legend=False)\n",
        "axes[0].set_title('IMPORTANCIA DE LAS VARIABLES - RANDOM FOREST', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('IMPORTANCIA', fontsize=10, fontweight='bold')\n",
        "axes[0].set_ylabel('VARIABLES', fontsize=10, fontweight='bold')\n",
        "\n",
        "gbm_plot_data = importance_df.sort_values('GBM', ascending=False).head(15)\n",
        "sns.barplot(x='GBM', y='Variable', data=gbm_plot_data, ax=axes[1], palette='plasma', hue='Variable', legend=False)\n",
        "axes[1].set_title('IMPORTANCIA DE LAS VARIABLES - GBM', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('IMPORTANCIA', fontsize=10, fontweight='bold')\n",
        "axes[1].set_ylabel('VARIABLES', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K2iNqfH969m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_table = importance_df.sort_values(by='RandomForest', ascending=False).reset_index(drop=True).head(15)\n",
        "print(\"TABLA COMPARATIVA DE LA IMPORTANCIA DE LAS VARIABLES\")\n",
        "print(\"-\" * 50)\n",
        "print(comparison_table)"
      ],
      "metadata": {
        "id": "f_Cy0xL7yxqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "features_to_plot = [\n",
        "    'standardscaler__meses_de_contrato',\n",
        "    'standardscaler__cargos_mensuales',\n",
        "    'onehotencoder__tipo_de_contrato_Mes a mes',\n",
        "    'onehotencoder__forma_de_pago_Cheque electr칩nico',\n",
        "    'onehotencoder__tipo_de_contrato_Dos a침os',\n",
        "    'onehotencoder__servicio_internet_Fibra 칩ptica'\n",
        "]\n",
        "\n",
        "fig, axs = plt.subplots(2, 3, figsize=(30, 10))\n",
        "palette = sns.color_palette(\"Set2\", len(features_to_plot))\n",
        "line_kw_list = [{\"color\": c, \"linewidth\": 2, \"linestyle\": \"--\"} for c in palette]\n",
        "fig.suptitle('GR츼FICOS DE DEPENDENCIA PARCIAL', fontsize=18, fontweight='bold')\n",
        "\n",
        "for i, feature in enumerate(features_to_plot):\n",
        "    ax = axs.ravel()[i]\n",
        "\n",
        "    PartialDependenceDisplay.from_estimator(\n",
        "        modelo3,\n",
        "        X_train_selected,\n",
        "        [feature],\n",
        "        ax=ax,\n",
        "        kind='average',\n",
        "        grid_resolution=100,\n",
        "        line_kw=line_kw_list[i]\n",
        "    )\n",
        "\n",
        "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VZOdbo3118Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conclusi칩n Final***"
      ],
      "metadata": {
        "id": "912o1Jl5DvNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "游댳 Introducci칩n:\n",
        "\n",
        "Este informe enmarca la 2da parte del proyecto de Telecom X, una empresa que enfrenta una alarmante tasa de cancelaciones de su clientela. El objetivo principal fue dise침ar modelos predictivos, realizar un an치lisis de los factores que m치s influyen en la cancelaci칩n y emprender acciones para mejorar la retenci칩n de clientes.\n",
        "\n",
        "El proyecto se desarroll칩 a partir del DataFrame ya procesado en la primera parte, incluyendo la separaci칩n de datos, codificaci칩n, balanceo de clases, y la posterior creaci칩n y evaluaci칩n de los modelos.\n",
        "\n",
        "---\n",
        "\n",
        "游댳 Objetivos:\n",
        "\n",
        "Debido a que la adquisici칩n de nuevos clientes es significativamente m치s costosa que la retenci칩n de los existentes, se ha llevado a cabo un an치lisis de para construir modelos predictivos que permitan:\n",
        "\n",
        "1. Identificar y cuantificar los principales factores que conducen a la cancelaci칩n.\n",
        "2. Minimizar la p칠rdida de clientes.\n",
        "3. Entender el comportamiento diferencial de los modelos predictivos.\n",
        "4. Proponer un conjunto de estrategias de retenci칩n para mitigar los riesgos identificados.\n",
        "\n",
        "---\n",
        "\n",
        "游댳 Metodolog칤a:\n",
        "\n",
        "Se entrenaron 3 modelos de clasificaci칩n reconocidos por su alto rendimiento, los cuales son Logistic Regression (LR), Random Forest (RF), Gradient Boosting Machine (GBM). Debido al primer modelo que se us칩, fue necesario normalizar los datos en el encoding mediante el StandardScaler(). A continuaci칩n, se detalla su impacto en los 3 modelos:\n",
        "\n",
        "- La Regresi칩n Log칤stica calcula una funci칩n lineal de los predictores para estimar probabilidades. Si las variables tienen escalas muy distintas, aquellas con escalas mayores tienden a dominar la magnitud de los coeficientes, afectando negativamente la convergencia del algoritmo de optimizaci칩n. Los beneficios de normalizar son: una mejora en la estabilidad num칠rica, una aceleraci칩n en el proceso de entrenamiento y permite una comparaci칩n m치s justa entre coeficientes (aunque no directamente interpretable como importancia).\n",
        "\n",
        "- El Random Forest y Gradiente Boosting Machine no requieren normalizaci칩n ya que construyen 치rboles de decisi칩n que dividen los datos seg칰n umbrales en variables individuales. Este proceso no depende de las distancias ni de la magnitud relativa de las variables, sino de su capacidad para dividir los datos de manera informativa.\n",
        "\n",
        "De estos 3 modelos, el Gradient Boostin Machine present칩 las mejores m칠tricas individualmente, no obstante, para obtener un leve aumento en las estad칤sticas, se decidi칩 usar un modelo de ensamble mediante VotingClassifier(). Con este m칠todo se emplearon los modelos Random Forest (bagging) y Gradient Boosting Machine (boosting). Esta combinaci칩n permite capturar distintas formas de aprender patrones en los datos, potenciando la capacidad de generalizaci칩n del modelo final.\n",
        "\n",
        "---\n",
        "\n",
        "游댳 An치lisis de los factores clave de cancelaci칩n:\n",
        "\n",
        "El an치lisis de los gr치ficos revel칩 patrones claros que los modelos aprendieron para predecir el churn. ***La conclusi칩n principal es que los factores contractuales son, por amplio margen, los predictores m치s potentes y fiables. Otros factores, como el m칠todo de pago y el tipo de servicio, aportan informaci칩n secundaria pero comercialmente relevante***.\n",
        "\n",
        "La evidencia m치s contundente se encuentra en las variables relacionadas con la duraci칩n del contrato. El gr치fico de meses contratados muestra una relaci칩n inversa y casi lineal: A mayor duraci칩n, menor probabilidad de cancelaci칩n. Esta tendencia se refuerza con los gr치ficos categ칩ricos, donde tener un contrato \"Mes a Mes\" incrementa significativamente el riesgo de churn, mientras que los contratos de \"Dos A침os\" lo reducen. As칤, los tres gr치ficos narran una historia coherente: *La estabilidad contractual es el pilarde la retenci칩n de clientes seg칰n los modelos*.\n",
        "\n",
        "M치s all치 de los contratos, emergen dos factores relevantes. Primero, **el uso del cheque electr칩nico como m칠todo de pago se asocia con una mayor probabilidad de cancelaci칩n**. Esto podr칤a deberse a que es un medio menos automatizado o a que refleja un perfil de cliente con menor estabilidad financiera o digital.\n",
        "\n",
        "En segundo lugar, de forma contraintuitiva, **ser cliente de fibra 칩ptica tambi칠n incrementa el riesgo**. Este hallazgo sugiere que el servicio premium no cumple con las expectativas, presenta problemas de fiabilidad o tiene un precio percibido como injusto, lo que eleva la probabilidad de churn.\n",
        "\n",
        "Por 칰ltimo, **los cargos mensuales presentan un comportamiento m치s complejo**. A diferencia de otras variables, no muestran una tendencia clara: su relaci칩n con la cancelaci칩n es vol치til y depende de interacciones con otros factores. Por ejemplo, un precio alto puede ser aceptable en un contrato largo, pero riesgoso en uno de mes a mes. Como los modelos captaron esta complejidad, una pol칤tica de precios simple no ser치 efectiva, su impacto debe analizarse en funci칩n del perfil completo del cliente.\n",
        "\n",
        "De este modo, se identifican tres 치reas principales que impulsan la cancelaci칩n:\n",
        "\n",
        "---\n",
        "\n",
        "*1. Factor dominante: La estabilidad contractual (gr치ficos PDP y de correlaci칩n)*\n",
        "\n",
        "- **La duraci칩n y el tipo de contrato son los predictores m치s potentes** seg칰n los modelos Random Forest y GBM.\n",
        "\n",
        "- **El contrato \"Mes a Mes\" representa el principal indicador de riesgo**. Los gr치ficos PDP muestran que este tipo de contrato eleva notablemente la probabilidad de cancelaci칩n, y el modelo GBM le asigna una importancia cr칤tica.\n",
        "\n",
        "- En contraste, **la duraci칩n del contrato act칰a como el principal factor de retenci칩n**. Los gr치ficos de correlaci칩n y el boxplot indican que a mayor cantidad de meses contratados, menor es el riesgo. Los clientes con contrato de 2 a침os son los m치s leales.\n",
        "\n",
        "---\n",
        "\n",
        "*2. Factores econ칩micos y de conveniencia (gr치ficos PDP y boxplot)*\n",
        "\n",
        "- **El pago mediante cheque electr칩nico se asocia con mayor probabilidad de churn**, posiblemente por ser un m칠todo menos autom치tico o un indicador de menor estabilidad del cliente.\n",
        "\n",
        "- **Los cargos mensuales no presentan una relaci칩n lineal clara** en los gr치ficos PDP, pero el boxplot muestra que los clientes con cargos m치s altos tienden a cancelar m치s. Por lo que este efecto depende del contexto: Un precio elevado puede ser aceptables si est치 respaldado por contratos largos o servicios de valor significantes.\n",
        "\n",
        "---\n",
        "\n",
        "*3. Calidad percibida del servicio (gr치fico PDP)*\n",
        "\n",
        "- De manera sorprendente, **ser cliente de fibra 칩ptica se vincula con mayor riesgo de cancelaci칩n**. Esto podr칤a deberse a una brecha entre las expectativas creadas y la experiencia real, precios poco competitivos o deficiencias t칠cnicas.\n",
        "\n",
        "---\n",
        "\n",
        "游댳 Conclusi칩n:\n",
        "\n",
        "Tanto los modelos predictivos como el modelo h칤brido han proporcionado una hoja de ruta clara para enfocar los esfuerzos de retenci칩n. Ahora se sabe que **la batalla por la retenci칩n se gana en la estructura del contrato**. Al enfocar los recursos en migrar a los clientes de alto riesgo a planes m치s estables y en investigar las deficiencias operativas de servicios claves, la empresa puede construir una base de clientes m치s leal y reducir significativamente la tasa de cancelaci칩n a largo plazo.\n",
        "\n",
        "Para complementar estas decisiones se utiliz칩 Feature Importance para analizar la importancia de las variables de mayor a menor influencia en la predicci칩n, Gr치ficos de Dependencia Parcial (PDP) para visualizar c칩mo afecta el cambio en una variable espec칤fica a la probabilidad de cancelaci칩n y entender la direcci칩n y magnitud del efecto.\n",
        "\n",
        "Eso s칤, aunque el modelo de Random Forest y GMB tuvieron diferencias en la distribuci칩n de la importancia de las variables, *ambos modelos mostraron un alto grado de acuerdo en la identificaci칩n de las variables m치s importantes*, lo que refuerza la validez de los hallazgos.\n",
        "\n",
        "---\n",
        "\n",
        "游댳 Recomendaciones:\n",
        "\n",
        "Tras mi conclusi칩n y an치lisis, recomiendo las siguientes estrategias:\n",
        "\n",
        "1. ***Fortalecer el compromiso contractual***. El objetivo es reducir la cantidad de clientes con contrato \"Mes a mes\". Para lograrlo, la empresa deber칤a implementar campa침as proactivas dirigidas a quienes ya llevan m치s de 3 a 6 meses bajo esta modalidad, ofreci칠ndoles incentivos concretos para migrar a contratos de 1 o 2 a침os, como descuentos en la tarifa mensual, un mes gratuito o servicios adicionales sin cargo. Adem치s, se recomienda utilizar el modelo predictivo para identificar y priorizar a los clientes con mayor probabilidad de cancelar.\n",
        "\n",
        "2. ***Optimizar la experiencia de pago***. El objetivo es reducir la fricci칩n y aumentar la retenci칩n entre quienes utilizan cheque electr칩nico. Para ello, sugiero lanzar una campa침a preventiva que comunique los beneficios de los m칠todos autom치ticos como tarjeta de cr칠dito o d칠bito, acompa침ada de un incentivo menor (como un descuento 칰nico) para quienes realicen el cambio. Tambi칠n es clave analizar las tasas de fallo de este medio de pago para identificar si las cancelaciones se deben a problemas operativos.\n",
        "\n",
        "3. ***Auditar y mejorar los servicios, especialmente la fibra 칩ptica***. Es necesario comprender por qu칠 un producto considerado premium se asocia a una mayor tasa de cancelaci칩n. Recomiendo lanzar encuestas de satisfacci칩n espec칤ficas para los usuarios de fibra 칩ptica y dem치s servicios y revisar los registros del centro de atenci칩n al cliente para detectar patrones de queja (velocidad, interrupciones, instalaci칩n). Por 칰ltimo, conviene realizar un benchmark de precios y rendimiento frente a competidores en las zonas con cobertura y otros servicios.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "游댳 Final:\n",
        "\n",
        "Si bien, todo el an치lisis ETL permiti칩 sentar las bases para un sistema de predicci칩n, una optimizaci칩n de ofertas y una retenci칩n de clientes. Ahora, la empresa de Telecom X tiene todas las herramientas necesarias para reducir el churn."
      ],
      "metadata": {
        "id": "YHpkUTIQEDts"
      }
    }
  ]
}