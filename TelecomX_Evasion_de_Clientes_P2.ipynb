{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DXBPIKIN1WrU",
        "oJuxvchfMi_m",
        "TfQ9NkfGfkP9",
        "aQYsoKI7Xpqo",
        "2JSzaC_VXLoB",
        "rgwXxN1lzbKa",
        "xTAbGXTyTGai",
        "L_JY_JFQx4qu",
        "yPDzJHoQPmkP",
        "99uKUJNo6WSR",
        "2g1eCBiv62ME",
        "912o1Jl5DvNv"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AVIDALESB/TelecomX-Evasion-de-Clientes-P2/blob/main/TelecomX_Evasion_de_Clientes_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Extracción del Archivo Tratado***\n",
        "\n",
        "> Agregar bloque entrecomillado\n",
        "\n"
      ],
      "metadata": {
        "id": "DXBPIKIN1WrU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_-cUTTaxLPe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos = pd.read_csv('/content/df.csv')"
      ],
      "metadata": {
        "id": "jdvwE3MY1s1E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "259c6704-f00f-4710-8abf-d6f037eb00e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/df.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3858360656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/df.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datos['género'] = datos['género'].map({'Masculino': 0, 'Femenino': 1})"
      ],
      "metadata": {
        "id": "a1hTFZGa81xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos = datos.rename(columns={'cuidadano_mayor': 'ciudadano_mayor'})"
      ],
      "metadata": {
        "id": "xSQMaDULLMdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos"
      ],
      "metadata": {
        "id": "tcDU2nwc10jb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.info()"
      ],
      "metadata": {
        "id": "bgWdUOjK19bd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.isnull().sum()"
      ],
      "metadata": {
        "id": "bMcVQq2h7hu0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Eliminación de las Columnas Irrelevantes***"
      ],
      "metadata": {
        "id": "oJuxvchfMi_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(datos.nunique().sort_values())"
      ],
      "metadata": {
        "id": "uMJ_prdmMjtm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_unicas = [col for col in datos.columns if datos[col].nunique() == 1]\n",
        "print(f'Las columnas con valores únicos son: {columnas_unicas}')"
      ],
      "metadata": {
        "id": "6oHQV6IdMnHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacion = datos.select_dtypes(include=['float64', 'int64']).corr().abs()\n",
        "correlacion"
      ],
      "metadata": {
        "id": "AeG1XpBlMnn1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado que cuentas_diarias y cargos_mensuales tienen la misma correlatividad, conviene eliminar cuentas_diarias.\n",
        "# Otras columnas que se eliminarán serán id_cliente porque tiene identificadores únicos y cantidad_servicios por su alta correlación en columnas irrelevantes para relacionarlas con churn.\n",
        "# También, otras columnas que se eliminará por su baja correlacion con churn y el resto de columnas serán servicio_telefonico y género.\n",
        "# Si bien cargos_totales puede ser útil con churn, su multicolinealidad del 0.82 con meses_de_contrato la hace una columna inviable para el modelo."
      ],
      "metadata": {
        "id": "cHZJwW1sMnlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reducido = datos.drop(columns = ['id_cliente', 'cuentas_diarias', 'cantidad_servicios', 'servicio_telefonico', 'cargos_totales', 'género'])\n",
        "df_reducido.info()"
      ],
      "metadata": {
        "id": "halwRKDdMnix",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Verificación de la Proporción de Cancelación (Churn)***"
      ],
      "metadata": {
        "id": "TfQ9NkfGfkP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "valores = df_reducido['churn'].value_counts()\n",
        "porcentajes = df_reducido['churn'].value_counts(normalize=True) * 100\n",
        "\n",
        "df_aux = df_reducido['churn'].map({0: 'Permanece', 1: 'Abandonó'}).to_frame(name='Estado')\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(7, 7))\n",
        "colores = ['#0083d5', '#d56e00']\n",
        "\n",
        "ax = sns.countplot(x='Estado', data=df_aux, color=None)\n",
        "for patch, color in zip(ax.patches, colores):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "plt.title('PROPORCIÓN DE CANCELACIÓN (CHURN)', fontsize=14, fontweight='bold', loc='center')\n",
        "plt.xlabel('ESTADO DEL CLIENTE', fontsize=10, fontweight='bold')\n",
        "plt.ylabel('NÚMERO DE CLIENTES', fontsize=10, fontweight='bold')\n",
        "\n",
        "for p in ax.patches:\n",
        "    cantidad = int(p.get_height())\n",
        "    porcentaje = cantidad / len(df_reducido['churn']) * 100\n",
        "    ax.annotate(f'{cantidad} / {porcentaje:.1f}%',\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='bottom', fontsize=10, color='black',\n",
        "                xytext=(0, 1), textcoords='offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zMyhWpPJmWQ0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Análisis de Correlación***"
      ],
      "metadata": {
        "id": "aQYsoKI7Xpqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df_reducido.select_dtypes(include=['float64', 'int64']).corr().abs()"
      ],
      "metadata": {
        "id": "85YiJyKsYQaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.imshow(\n",
        "    df_corr,\n",
        "    text_auto=\".2f\",\n",
        "    color_continuous_scale=\"viridis\",\n",
        "    aspect=\"auto\",\n",
        "    title=\"MATRIZ DE CORRELACIÓN\"\n",
        ")\n",
        "fig.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RaWUH2ryZq6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Al analizar la primera columna de la matriz, se puede identificar claramente los factores más influyentes.\n",
        "# El predictor principal es meses_de_contrato con una correlación del 0.34. La interpretación es que a mayor antigüedad, menor es la probabilidad de cancelar.\n",
        "# Después hay predictores secundarios cuyo impacto es moderado. Por ejemplo: cargos_mensuales y factura_en_linea (ambas con 0.18) mantienen un peso considerable.\n",
        "# Ambos intuyen que los clientes con cargos más altos o con factura online tienen una leve tendencia mayor a cancelar.\n",
        "# El grupo de variables demográficas ahora tiene más protagonismo (dependientes con 0.15, pareja con 0.14 y ciudadano_mayor con 0.14), aunque su impacto individual es débil.\n",
        "# En conjunto le dan al modelo un perfil claro del cliente. Por ejemplo: Ser un ciudadano mayor, tener pareja o dependientes tiene una influencia positiva muy leve en la probabilidad de abandono.\n",
        "\n",
        "# Otras conclusiones a sacar son que la correlación más fuerte en toda la matriz es entre pareja y dependientes con 0.45, por lo que quienen tengan pareja son más propensos a tener dependientes.\n",
        "# Otra correlación moderada es entre pareja y meses_de_contrato con 0.38, esto sugiere que los clientes con pareja tienden a tener contratos de mayor duración.\n",
        "# Y por último, la correlación entre factura_en_linea y cargos_mensuales es moderada con 0.35, eso indica que los clientes con cargos mensuales más altos son más propensos a usar la facturación en línea."
      ],
      "metadata": {
        "id": "4D3t621fkIIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Análisis Dirigido***"
      ],
      "metadata": {
        "id": "2JSzaC_VXLoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import Line2D\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "ax = sns.boxplot(\n",
        "    data=df_reducido,\n",
        "    x='churn',\n",
        "    y='meses_de_contrato',\n",
        "    hue='churn',\n",
        "    palette={0: '#0083d5', 1: '#d56e00'},\n",
        "    legend=False,\n",
        "    medianprops={'linewidth': 2}\n",
        ")\n",
        "\n",
        "for i, (name, group) in enumerate(df_reducido.groupby('churn')):\n",
        "    ax.hlines(\n",
        "        y=group['meses_de_contrato'].mean(),\n",
        "        xmin=i - 0.4,\n",
        "        xmax=i + 0.4,\n",
        "        color='cyan',\n",
        "        linestyle='--',\n",
        "        linewidth = 2\n",
        "    )\n",
        "\n",
        "plt.title(\"DISTRIBUCIÓN DE LOS MESES DE CONTRATO SEGÚN LA CANCELACIÓN\", fontsize=14, fontweight='bold', loc = 'center')\n",
        "plt.xlabel(\"ESTADO DEL CLIENTE\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"MESES DE CONTRATO\", fontsize=12, fontweight='bold')\n",
        "\n",
        "legend_elements = [\n",
        "    Line2D([0], [0], color='cyan', linestyle='--', label='Media'),\n",
        "    Line2D([0], [0], color='black', label='Mediana')\n",
        "]\n",
        "\n",
        "ax.legend(handles=legend_elements, loc='upper center')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XAf5UESheP9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En el grupo 0 la mediana es ligeramente más alta que la media (aunque ambas tienen casi el mismo valor, aproximadamente 38 meses).\n",
        "# Hay una amplia dispersión en el rango de los meses (De 1 a más de 70), lo que indica una clientela con permanencias muy diversas.\n",
        "# La mayoría de los clientes que no cancelaron han permanecido mucho más tiempo con la empresa.\n",
        "# Mientras tanto, en el grupo 1, la mediana está entre 10 y 12 meses y la media está entre 19 y 20 meses, por lo que es más alta que la mediana.\n",
        "# Los clientes que cancelan tienden a tener menos meses de contrato.\n",
        "\n",
        "# Esto esto indica una relación entre las variables: Cuanto más meses de contrato, menor es la probabilidad de cancelación, por lo que la retención de largo plazo disminuye la tasa de churn."
      ],
      "metadata": {
        "id": "OYGwt7zyjSds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import Line2D\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(7, 6))\n",
        "\n",
        "ax = sns.boxplot(\n",
        "    data=df_reducido,\n",
        "    x='churn',\n",
        "    y='cargos_mensuales',\n",
        "    hue='churn',\n",
        "    palette={0: '#0083d5', 1: '#d56e00'},\n",
        "    legend=False,\n",
        "    medianprops={'linewidth': 2}\n",
        ")\n",
        "\n",
        "for i, (name, group) in enumerate(df_reducido.groupby('churn')):\n",
        "    ax.hlines(\n",
        "        y=group['cargos_mensuales'].mean(),\n",
        "        xmin=i - 0.4,\n",
        "        xmax=i + 0.4,\n",
        "        color='cyan',\n",
        "        linestyle='--',\n",
        "        linewidth = 2\n",
        "    )\n",
        "\n",
        "plt.title(\"DISTRIBUCIÓN DE LOS CARGOS MENSUALES SEGÚN LA CANCELACIÓN\", fontsize=14, fontweight='bold', loc = 'center')\n",
        "plt.xlabel(\"ESTADO DEL CLIENTE\", fontsize=12, fontweight='bold')\n",
        "plt.ylabel(\"CARGOS MENSUALES\", fontsize=12, fontweight='bold')\n",
        "\n",
        "legend_elements = [\n",
        "    Line2D([0], [0], color='cyan', linestyle='--', label='Media'),\n",
        "    Line2D([0], [0], color='black', label='Mediana')\n",
        "]\n",
        "\n",
        "ax.legend(handles=legend_elements, loc='upper center')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zaB6DyW5iNdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En este grupo 0 la mediana de cargos mensuales es cercana a 65 al igual que la media, solo que esta es mínimamente menor a la mediana (aproximadamente 62).\n",
        "# Existe una distribución amplia pero es relativamente más baja en valores.\n",
        "# En cambio, en el grupo 1 la mediana ronda casi los 80 (es mayor que el grupo que no canceló) y la media ronda si los 75, siendo más alto que el grupo 0.\n",
        "# Esto demuestra que muchos clientes que cancelan tienen cargos mensuales más altos.\n",
        "\n",
        "# En este boxplot existe una relación inversa entre las variables: Los clientes con cargos más altos tienden a cancelar más.\n",
        "# Esto podría deberse a una percepción de alto costo o baja percepción de valor por el precio pagado."
      ],
      "metadata": {
        "id": "U8S8oTDsrdn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Separación de los Datos***"
      ],
      "metadata": {
        "id": "rgwXxN1lzbKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_reducido.columns"
      ],
      "metadata": {
        "id": "Er_DacP0hy_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reducido"
      ],
      "metadata": {
        "id": "XVl5p1i-hy7_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_reducido.drop('churn', axis = 1)\n",
        "y = df_reducido['churn']"
      ],
      "metadata": {
        "id": "vLHkJzMghy5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N7q3axlUhyuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tdBEUmeZh2je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify = y, random_state=42)"
      ],
      "metadata": {
        "id": "iIF7dY_Zzem4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_categoricas = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "columnas_numericas = ['meses_de_contrato', 'cargos_mensuales']"
      ],
      "metadata": {
        "id": "Y2MsPPT1lNtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Encoding***"
      ],
      "metadata": {
        "id": "xTAbGXTyTGai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "i500IcOcTUD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = make_column_transformer((OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas), (StandardScaler(), columnas_numericas), remainder='passthrough', sparse_threshold=0)"
      ],
      "metadata": {
        "id": "xNNqeQ75Tdfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded = one_hot.fit_transform(X_train)\n",
        "X_test_encoded = one_hot.transform(X_test)"
      ],
      "metadata": {
        "id": "9NEgdZ0eTdcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot.get_feature_names_out()"
      ],
      "metadata": {
        "id": "RMtdaN0LTdaG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df = pd.DataFrame(X_train_encoded, columns = one_hot.get_feature_names_out())\n",
        "X_train_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7gtrHKsSTdXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df.info()"
      ],
      "metadata": {
        "id": "12sWeu2gTdVL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_df = pd.DataFrame(X_test_encoded, columns=one_hot.get_feature_names_out())\n",
        "X_test_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Rpxqf-R7iTOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_df.info()"
      ],
      "metadata": {
        "id": "t2-qd_9-ie2O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_corr = X_train_df.copy()\n",
        "X_train_corr['churn'] = y_train.reset_index(drop=True)\n",
        "\n",
        "correlaciones = X_train_corr.corr()['churn'].sort_values(ascending=False)\n",
        "print(correlaciones)"
      ],
      "metadata": {
        "id": "bN2be346G7n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "modelo_l1 = LogisticRegression(penalty='l1', solver='liblinear', random_state=42)\n",
        "selector = RFECV(estimator=modelo_l1, step=1, cv=5, scoring='accuracy')\n",
        "selector.fit(X_train_df, y_train)\n",
        "\n",
        "selected_features = X_train_df.columns[selector.support_]\n",
        "print(\"Número óptimo de variables:\", selector.n_features_)"
      ],
      "metadata": {
        "id": "FS880Y5rPixe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "modelo_base = LogisticRegression(penalty='l1', solver='liblinear', C = 10, random_state=42)\n",
        "selector = RFE(estimator=modelo_base, n_features_to_select=29)\n",
        "\n",
        "selector.fit(X_train_df, y_train)\n",
        "selected_features_mask = selector.support_\n",
        "selected_features = X_train_df.columns[selected_features_mask]\n",
        "\n",
        "X_train_selected = X_train_df[selected_features]\n",
        "X_test_selected = X_test_df[selected_features]\n",
        "\n",
        "print(\"Las variables seleccionadas son:\")\n",
        "print(selected_features)"
      ],
      "metadata": {
        "id": "5tOZhrqgNjEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Balanceo de las Clases***"
      ],
      "metadata": {
        "id": "L_JY_JFQx4qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_bal, y_train_bal = ros.fit_resample(X_train_selected, y_train)\n",
        "\n",
        "print(\"Distribución original:\", Counter(y))\n",
        "print(\"Distribución del entrenamiento antes del balanceo:\", Counter(y_train))\n",
        "print(\"Distribución del entrenamiento balanceado:\", Counter(y_train_bal))\n",
        "\n",
        "counter = Counter(y_train_bal)\n",
        "if len(set(counter.values())) == 1:\n",
        "    print(\"Las clases están perfectamente balanceadas.\")\n",
        "else:\n",
        "    print(\"Las clases NO están balanceadas perfectamente.\")"
      ],
      "metadata": {
        "id": "ZXH0AwCpyCJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Normalización o Estandarización***"
      ],
      "metadata": {
        "id": "yPDzJHoQPmkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En esta etapa, no hace falta normalizar o estandarizar los datos antes del entrenamiento de modelos ya que si bien hay algunos que lo necesitan.\n",
        "# La realidad es que ya se aplicó la estandarización automáticamente a las variables numéricas mediante StandardScaler dentro del make_column_transformer.\n",
        "# Eso si, las variables binarias ('ciudadano_mayor', 'pareja', 'dependientes' y 'factura_en_linea') no se estandarizaron debido a que su escala no afecta a los algoritmos"
      ],
      "metadata": {
        "id": "9zyhRWqHm6ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Creación y Evaluación de los Modelos***"
      ],
      "metadata": {
        "id": "99uKUJNo6WSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluar_modelo(y_test, y_pred):\n",
        "  print(\"Resultados para el modelo:\")\n",
        "  print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "  print(f\"Precision: {precision_score(y_test, y_pred):.2f}\")\n",
        "  print(f\"Recall: {recall_score(y_test, y_pred):.2f}\")\n",
        "  print(f\"F1: {f1_score(y_test, y_pred):.2f}\")"
      ],
      "metadata": {
        "id": "-uYGCxMnXYPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "modelo = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    C=10,\n",
        "    class_weight= 'balanced',\n",
        "    solver='liblinear',\n",
        "    max_iter=5000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo.fit(X_train_bal, y_train_bal)\n",
        "y_modelo_lr = modelo.predict(X_test_selected)\n",
        "evaluar_modelo(y_test, y_modelo_lr)"
      ],
      "metadata": {
        "id": "07S6bih8pAQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "modelo2 = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=100,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=10,\n",
        "    max_features='log2',\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo2.fit(X_train_bal, y_train_bal)\n",
        "y_modelo_rf = modelo2.predict(X_test_selected)\n",
        "evaluar_modelo(y_test, y_modelo_rf)"
      ],
      "metadata": {
        "id": "rAbNNXmllBU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "modelo3 = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo3.fit(X_train_bal, y_train_bal)\n",
        "y_modelo_gb = modelo3.predict(X_test_selected)\n",
        "evaluar_modelo(y_test, y_modelo_gb)"
      ],
      "metadata": {
        "id": "Q04L3BVwnRL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "import numpy as np\n",
        "\n",
        "modelo_rf = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=100,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=10,\n",
        "    max_features='log2',\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo_gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo_voto = VotingClassifier(estimators=[('rf', modelo_rf), ('gb', modelo_gb)],voting='soft')\n",
        "modelo_voto.fit(X_train_bal, y_train_bal)\n",
        "y_proba = modelo_voto.predict_proba(X_test_selected)[:, 1]\n",
        "umbral = 0.45\n",
        "y_pred = (y_proba >= umbral).astype(int)\n",
        "evaluar_modelo(y_test, y_pred)"
      ],
      "metadata": {
        "id": "OZESRJb52UEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred, name = 'Modelo Híbrido');"
      ],
      "metadata": {
        "id": "iPoVGTE8bTsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
        "visualizacion_matriz = ConfusionMatrixDisplay(confusion_matrix = matriz_confusion, display_labels = ['Se quedó', 'Abandonó'])\n",
        "visualizacion_matriz.plot();"
      ],
      "metadata": {
        "id": "xUbWIii9eAaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Análisis de la Importancia de las Variables según los Modelos***"
      ],
      "metadata": {
        "id": "2g1eCBiv62ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_importance = modelo2.feature_importances_\n",
        "gb_importance = modelo3.feature_importances_\n",
        "\n",
        "feature_names = X_train_selected.columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'Variable': feature_names,\n",
        "    'RandomForest': rf_importance,\n",
        "    'GBM': gb_importance\n",
        "})\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "rf_plot_data = importance_df.sort_values('RandomForest', ascending=False).head(15)\n",
        "sns.barplot(x='RandomForest', y='Variable', data=rf_plot_data, ax=axes[0], palette='viridis', hue='Variable', legend=False)\n",
        "axes[0].set_title('IMPORTANCIA DE LAS VARIABLES - RANDOM FOREST', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('IMPORTANCIA', fontsize=10, fontweight='bold')\n",
        "axes[0].set_ylabel('VARIABLES', fontsize=10, fontweight='bold')\n",
        "\n",
        "gbm_plot_data = importance_df.sort_values('GBM', ascending=False).head(15)\n",
        "sns.barplot(x='GBM', y='Variable', data=gbm_plot_data, ax=axes[1], palette='plasma', hue='Variable', legend=False)\n",
        "axes[1].set_title('IMPORTANCIA DE LAS VARIABLES - GBM', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('IMPORTANCIA', fontsize=10, fontweight='bold')\n",
        "axes[1].set_ylabel('VARIABLES', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K2iNqfH969m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_table = importance_df.sort_values(by='RandomForest', ascending=False).reset_index(drop=True).head(15)\n",
        "print(\"TABLA COMPARATIVA DE LA IMPORTANCIA DE LAS VARIABLES\")\n",
        "print(\"-\" * 50)\n",
        "print(comparison_table)"
      ],
      "metadata": {
        "id": "f_Cy0xL7yxqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "features_to_plot = [\n",
        "    'standardscaler__meses_de_contrato',\n",
        "    'standardscaler__cargos_mensuales',\n",
        "    'onehotencoder__tipo_de_contrato_Mes a mes',\n",
        "    'onehotencoder__forma_de_pago_Cheque electrónico',\n",
        "    'onehotencoder__tipo_de_contrato_Dos años',\n",
        "    'onehotencoder__servicio_internet_Fibra óptica'\n",
        "]\n",
        "\n",
        "fig, axs = plt.subplots(2, 3, figsize=(30, 10))\n",
        "palette = sns.color_palette(\"Set2\", len(features_to_plot))\n",
        "line_kw_list = [{\"color\": c, \"linewidth\": 2, \"linestyle\": \"--\"} for c in palette]\n",
        "fig.suptitle('GRÁFICOS DE DEPENDENCIA PARCIAL', fontsize=18, fontweight='bold')\n",
        "\n",
        "for i, feature in enumerate(features_to_plot):\n",
        "    ax = axs.ravel()[i]\n",
        "\n",
        "    PartialDependenceDisplay.from_estimator(\n",
        "        modelo3,\n",
        "        X_train_selected,\n",
        "        [feature],\n",
        "        ax=ax,\n",
        "        kind='average',\n",
        "        grid_resolution=100,\n",
        "        line_kw=line_kw_list[i]\n",
        "    )\n",
        "\n",
        "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VZOdbo3118Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conclusión Final***"
      ],
      "metadata": {
        "id": "912o1Jl5DvNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔹 Introducción:\n",
        "\n",
        "Este informe enmarca la 2da parte del proyecto de Telecom X, una empresa que enfrenta una alarmante tasa de cancelaciones de su clientela. El objetivo principal fue diseñar modelos predictivos, realizar un análisis de los factores que más influyen en la cancelación y emprender acciones para mejorar la retención de clientes.\n",
        "\n",
        "El proyecto se desarrolló a partir del DataFrame ya procesado en la primera parte, incluyendo la separación de datos, codificación, balanceo de clases, y la posterior creación y evaluación de los modelos.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 Objetivos:\n",
        "\n",
        "Debido a que la adquisición de nuevos clientes es significativamente más costosa que la retención de los existentes, se ha llevado a cabo un análisis de para construir modelos predictivos que permitan:\n",
        "\n",
        "1. Identificar y cuantificar los principales factores que conducen a la cancelación.\n",
        "2. Minimizar la pérdida de clientes.\n",
        "3. Entender el comportamiento diferencial de los modelos predictivos.\n",
        "4. Proponer un conjunto de estrategias de retención para mitigar los riesgos identificados.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 Metodología:\n",
        "\n",
        "Se entrenaron 3 modelos de clasificación reconocidos por su alto rendimiento, los cuales son Logistic Regression (LR), Random Forest (RF), Gradient Boosting Machine (GBM). Debido al primer modelo que se usó, fue necesario normalizar los datos en el encoding mediante el StandardScaler(). A continuación, se detalla su impacto en los 3 modelos:\n",
        "\n",
        "- La Regresión Logística calcula una función lineal de los predictores para estimar probabilidades. Si las variables tienen escalas muy distintas, aquellas con escalas mayores tienden a dominar la magnitud de los coeficientes, afectando negativamente la convergencia del algoritmo de optimización. Los beneficios de normalizar son: una mejora en la estabilidad numérica, una aceleración en el proceso de entrenamiento y permite una comparación más justa entre coeficientes (aunque no directamente interpretable como importancia).\n",
        "\n",
        "- El Random Forest y Gradiente Boosting Machine no requieren normalización ya que construyen árboles de decisión que dividen los datos según umbrales en variables individuales. Este proceso no depende de las distancias ni de la magnitud relativa de las variables, sino de su capacidad para dividir los datos de manera informativa.\n",
        "\n",
        "De estos 3 modelos, el Gradient Boostin Machine presentó las mejores métricas individualmente, no obstante, para obtener un leve aumento en las estadísticas, se decidió usar un modelo de ensamble mediante VotingClassifier(). Con este método se emplearon los modelos Random Forest (bagging) y Gradient Boosting Machine (boosting). Esta combinación permite capturar distintas formas de aprender patrones en los datos, potenciando la capacidad de generalización del modelo final.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 Análisis de los factores clave de cancelación:\n",
        "\n",
        "El análisis de los gráficos reveló patrones claros que los modelos aprendieron para predecir el churn. ***La conclusión principal es que los factores contractuales son, por amplio margen, los predictores más potentes y fiables. Otros factores, como el método de pago y el tipo de servicio, aportan información secundaria pero comercialmente relevante***.\n",
        "\n",
        "La evidencia más contundente se encuentra en las variables relacionadas con la duración del contrato. El gráfico de meses contratados muestra una relación inversa y casi lineal: A mayor duración, menor probabilidad de cancelación. Esta tendencia se refuerza con los gráficos categóricos, donde tener un contrato \"Mes a Mes\" incrementa significativamente el riesgo de churn, mientras que los contratos de \"Dos Años\" lo reducen. Así, los tres gráficos narran una historia coherente: *La estabilidad contractual es el pilarde la retención de clientes según los modelos*.\n",
        "\n",
        "Más allá de los contratos, emergen dos factores relevantes. Primero, **el uso del cheque electrónico como método de pago se asocia con una mayor probabilidad de cancelación**. Esto podría deberse a que es un medio menos automatizado o a que refleja un perfil de cliente con menor estabilidad financiera o digital.\n",
        "\n",
        "En segundo lugar, de forma contraintuitiva, **ser cliente de fibra óptica también incrementa el riesgo**. Este hallazgo sugiere que el servicio premium no cumple con las expectativas, presenta problemas de fiabilidad o tiene un precio percibido como injusto, lo que eleva la probabilidad de churn.\n",
        "\n",
        "Por último, **los cargos mensuales presentan un comportamiento más complejo**. A diferencia de otras variables, no muestran una tendencia clara: su relación con la cancelación es volátil y depende de interacciones con otros factores. Por ejemplo, un precio alto puede ser aceptable en un contrato largo, pero riesgoso en uno de mes a mes. Como los modelos captaron esta complejidad, una política de precios simple no será efectiva, su impacto debe analizarse en función del perfil completo del cliente.\n",
        "\n",
        "De este modo, se identifican tres áreas principales que impulsan la cancelación:\n",
        "\n",
        "---\n",
        "\n",
        "*1. Factor dominante: La estabilidad contractual (gráficos PDP y de correlación)*\n",
        "\n",
        "- **La duración y el tipo de contrato son los predictores más potentes** según los modelos Random Forest y GBM.\n",
        "\n",
        "- **El contrato \"Mes a Mes\" representa el principal indicador de riesgo**. Los gráficos PDP muestran que este tipo de contrato eleva notablemente la probabilidad de cancelación, y el modelo GBM le asigna una importancia crítica.\n",
        "\n",
        "- En contraste, **la duración del contrato actúa como el principal factor de retención**. Los gráficos de correlación y el boxplot indican que a mayor cantidad de meses contratados, menor es el riesgo. Los clientes con contrato de 2 años son los más leales.\n",
        "\n",
        "---\n",
        "\n",
        "*2. Factores económicos y de conveniencia (gráficos PDP y boxplot)*\n",
        "\n",
        "- **El pago mediante cheque electrónico se asocia con mayor probabilidad de churn**, posiblemente por ser un método menos automático o un indicador de menor estabilidad del cliente.\n",
        "\n",
        "- **Los cargos mensuales no presentan una relación lineal clara** en los gráficos PDP, pero el boxplot muestra que los clientes con cargos más altos tienden a cancelar más. Por lo que este efecto depende del contexto: Un precio elevado puede ser aceptables si está respaldado por contratos largos o servicios de valor significantes.\n",
        "\n",
        "---\n",
        "\n",
        "*3. Calidad percibida del servicio (gráfico PDP)*\n",
        "\n",
        "- De manera sorprendente, **ser cliente de fibra óptica se vincula con mayor riesgo de cancelación**. Esto podría deberse a una brecha entre las expectativas creadas y la experiencia real, precios poco competitivos o deficiencias técnicas.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 Conclusión:\n",
        "\n",
        "Tanto los modelos predictivos como el modelo híbrido han proporcionado una hoja de ruta clara para enfocar los esfuerzos de retención. Ahora se sabe que **la batalla por la retención se gana en la estructura del contrato**. Al enfocar los recursos en migrar a los clientes de alto riesgo a planes más estables y en investigar las deficiencias operativas de servicios claves, la empresa puede construir una base de clientes más leal y reducir significativamente la tasa de cancelación a largo plazo.\n",
        "\n",
        "Para complementar estas decisiones se utilizó Feature Importance para analizar la importancia de las variables de mayor a menor influencia en la predicción, Gráficos de Dependencia Parcial (PDP) para visualizar cómo afecta el cambio en una variable específica a la probabilidad de cancelación y entender la dirección y magnitud del efecto.\n",
        "\n",
        "Eso sí, aunque el modelo de Random Forest y GMB tuvieron diferencias en la distribución de la importancia de las variables, *ambos modelos mostraron un alto grado de acuerdo en la identificación de las variables más importantes*, lo que refuerza la validez de los hallazgos.\n",
        "\n",
        "---\n",
        "\n",
        "🔹 Recomendaciones:\n",
        "\n",
        "Tras mi conclusión y análisis, recomiendo las siguientes estrategias:\n",
        "\n",
        "1. ***Fortalecer el compromiso contractual***. El objetivo es reducir la cantidad de clientes con contrato \"Mes a mes\". Para lograrlo, la empresa debería implementar campañas proactivas dirigidas a quienes ya llevan más de 3 a 6 meses bajo esta modalidad, ofreciéndoles incentivos concretos para migrar a contratos de 1 o 2 años, como descuentos en la tarifa mensual, un mes gratuito o servicios adicionales sin cargo. Además, se recomienda utilizar el modelo predictivo para identificar y priorizar a los clientes con mayor probabilidad de cancelar.\n",
        "\n",
        "2. ***Optimizar la experiencia de pago***. El objetivo es reducir la fricción y aumentar la retención entre quienes utilizan cheque electrónico. Para ello, sugiero lanzar una campaña preventiva que comunique los beneficios de los métodos automáticos como tarjeta de crédito o débito, acompañada de un incentivo menor (como un descuento único) para quienes realicen el cambio. También es clave analizar las tasas de fallo de este medio de pago para identificar si las cancelaciones se deben a problemas operativos.\n",
        "\n",
        "3. ***Auditar y mejorar los servicios, especialmente la fibra óptica***. Es necesario comprender por qué un producto considerado premium se asocia a una mayor tasa de cancelación. Recomiendo lanzar encuestas de satisfacción específicas para los usuarios de fibra óptica y demás servicios y revisar los registros del centro de atención al cliente para detectar patrones de queja (velocidad, interrupciones, instalación). Por último, conviene realizar un benchmark de precios y rendimiento frente a competidores en las zonas con cobertura y otros servicios.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "🔹 Final:\n",
        "\n",
        "Si bien, todo el análisis ETL permitió sentar las bases para un sistema de predicción, una optimización de ofertas y una retención de clientes. Ahora, la empresa de Telecom X tiene todas las herramientas necesarias para reducir el churn."
      ],
      "metadata": {
        "id": "YHpkUTIQEDts"
      }
    }
  ]
}